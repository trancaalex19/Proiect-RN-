âœ¨ Etapa 3 â€“ Analiza È™i PregÄƒtirea Setului de Date

Proiect: Sistem de Verificare a AutenticitÄƒÈ›ii SemnÄƒturilor (SVAS)

Student: Tranca Alexandru-Constantin
Grupa: 634 AB
Universitatea POLITEHNICA BucureÈ™ti â€“ FIIR
Disciplina: ReÈ›ele Neuronale

ðŸ§­ 1. Introducere

AceastÄƒ etapÄƒ a proiectului vizeazÄƒ colectarea, curÄƒÈ›area È™i preprocesarea datelor necesare pentru antrenarea reÈ›elei neuronale.
Obiectivul principal a fost crearea unui dataset robust de semnÄƒturi digitale È™i dezvoltarea unei interfeÈ›e web (svas_web.py) care integreazÄƒ atÃ¢t partea de achiziÈ›ie de date, cÃ¢t È™i cea de antrenare È™i inferenÈ›Äƒ AI.

ðŸ“ 2. Structura Repository-ului

Structura actualizatÄƒ a proiectului la finalul Etapei 3:

SVAS-Project/
â”œâ”€â”€ README.md                # DocumentaÈ›ia curentÄƒ
â”œâ”€â”€ svas_web.py              # AplicaÈ›ia Web completÄƒ (InterfaÈ›Äƒ + Backend AI)
â”œâ”€â”€ semnatura_model.h5       # Modelul CNN antrenat È™i salvat
â”œâ”€â”€ dataset/                 # Setul de date colectat
â”‚   â”œâ”€â”€ Date autentice/      # 50 semnÄƒturi originale (Clasa 1)
â”‚   â””â”€â”€ Date false/          # 50 semnÄƒturi falsificate (Clasa 0)
â””â”€â”€ requirements.txt         # DependenÈ›e (tensorflow, flask, pillow, numpy)


ðŸ—‚ï¸ 3. Descrierea Setului de Date

3.1 Sursa Datelor

Origine: Date generate propriu (First-party data).

MetodÄƒ de achiziÈ›ie: Desenare digitalÄƒ folosind mouse/touchpad prin interfaÈ›a aplicaÈ›iei web dezvoltate (svas_web.py).

Volum: Dataset iniÈ›ial de 100 de imagini.

3.2 DistribuÈ›ia Claselor

S-a urmÄƒrit un echilibru perfect al claselor pentru a evita bias-ul reÈ›elei:

ClasÄƒ

EtichetÄƒ (Label)

Descriere

NumÄƒr Mostre

Autentic

1

SemnÄƒturi realizate de titular

50

Fals

0

ÃŽncercÄƒri de imitare sau semnÄƒturi aleatorii

50

ðŸ› ï¸ 4. Pipeline de Preprocesare

ÃŽnainte de a intra Ã®n ReÈ›eaua NeuronalÄƒ, imaginile brute trec printr-un proces automat de transformare implementat Ã®n Python:

Conversie Grayscale:

Transformare din RGB (3 canale) Ã®n L (1 canal).

EliminÄƒ informaÈ›ia inutilÄƒ de culoare, pÄƒstrÃ¢nd doar intensitatea liniilor.

Redimensionare (Resizing):

Toate imaginile sunt aduse la rezoluÈ›ia standard de 64x64 pixeli.

Motiv: Reducerea complexitÄƒÈ›ii computaÈ›ionale È™i standardizarea input-ului pentru CNN.

Normalizare:

Valorile pixelilor [0, 255] sunt Ã®mpÄƒrÈ›ite la 255.0.

Rezultat: Valori float Ã®n intervalul [0.0, 1.0], esenÈ›iale pentru convergenÈ›a rapidÄƒ a algoritmului Adam.

Data Augmentation (Implicit):

Variabilitatea naturalÄƒ a desenului cu mouse-ul funcÈ›ioneazÄƒ ca o augmentare a datelor, oferind diferenÈ›e subtile Ã®ntre mostre.

ðŸ§  5. Arhitectura Modelului (Pe scurt)

Modelul utilizat pentru validarea datelor Ã®n aceastÄƒ etapÄƒ este un CNN SecvenÈ›ial:

Input: (64, 64, 1)

Feature Extraction: 2 straturi Conv2D + MaxPooling2D pentru detectarea trÄƒsÄƒturilor vizuale.

Clasificare: Strat Dense (128 neuroni) + Dropout (0.5 pentru evitare overfitting).

Output: Sigmoid (probabilitate 0-1).

ðŸ’» 6. AplicaÈ›ia Web (Livrabil Etapa 3)

S-a dezvoltat un serviciu web (svas_web.py) folosind Flask care permite:

âœ… Desenarea semnÄƒturilor direct Ã®n browser (HTML5 Canvas).

âœ… Comunicarea asincronÄƒ cu backend-ul Python (Fetch API).

âœ… Re-antrenarea modelului la cerere, folosind datele din folderul dataset/.

âœ… Verificarea instantanee a semnÄƒturilor noi.

âœ”ï¸ 7. Status EtapÄƒ

[x] Colectare date: 50 Autentice / 50 False salvate Ã®n structura corectÄƒ.

[x] CurÄƒÈ›are date: Eliminare imagini goale/corupte.

[x] Implementare Preprocesare: Resize È™i Normalizare integrate Ã®n cod.

[x] Dezvoltare InterfaÈ›Äƒ: AplicaÈ›ie Web funcÈ›ionalÄƒ.

[x] Validare: Modelul antrenat atinge o acurateÈ›e preliminarÄƒ satisfÄƒcÄƒtoare (>90%).
e un readme in github
schimba mi niste cuvinte pe acolo
