ğŸ“˜ README â€“ Etapa 4

Disciplina: ReÈ›ele Neuronale

InstituÈ›ie: POLITEHNICA BucureÈ™ti â€“ FIIR

Student: Tranca Alexandru-Constantin

Data: 04.12.2025

Introducere

Acest document descrie activitÄƒÈ›ile realizate Ã®n Etapa 3, Ã®n care se analizeazÄƒ È™i se preproceseazÄƒ setul de date necesar proiectului â€Sistem de Verificare a AutenticitÄƒÈ›ii SemnÄƒturilor (SVAS)â€. Scopul etapei este pregÄƒtirea corectÄƒ a datelor pentru instruirea modelului RN, respectÃ¢nd bunele practici privind calitatea, consistenÈ›a È™i reproductibilitatea datelor.

1. Structura Repository-ului Github (versiunea Etapei 3)

SVAS-Project/
â”œâ”€â”€ README.md                # DocumentaÈ›ia tehnicÄƒ
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ datasets/            # Grafice È™i rapoarte distribuÈ›ie
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Date brute (imagini originale salvate din web app)
â”‚   â”œâ”€â”€ processed/           # Date curÄƒÈ›ate (transformate intern Ã®n memorie)
â”‚   â”œâ”€â”€ train/               # Set de instruire (gestionat automat)
â”‚   â”œâ”€â”€ validation/          # Set de validare (split 20%)
â”‚   â””â”€â”€ test/                # Date de testare live
â”œâ”€â”€ dataset/                 # Dataset-ul fizic
â”‚   â”œâ”€â”€ Date autentice/      # 50 imagini originale (Clasa 1)
â”‚   â””â”€â”€ Date false/          # 50 imagini falsificate (Clasa 0)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/       # Pipeline de redimensionare/normalizare
â”‚   â”œâ”€â”€ data_acquisition/    # Modulul svas_web.py
â”‚   â””â”€â”€ neural_network/      # Arhitectura CNN
â”œâ”€â”€ config/                  # ConfiguraÈ›ii (dimensiune 64x64)
â””â”€â”€ requirements.txt         # tensorflow, flask, pillow, numpy


2. Descrierea Setului de Date

2.1 Sursa datelor

Origine: Date generate propriu (First-party data) prin aplicaÈ›ia svas_web.py.

Modul de achiziÈ›ie: â˜‘ Senzori reali (Mouse / Touchpad) / â˜ Simulare / â˜ FiÈ™ier extern / â˜ Generare programaticÄƒ.

Perioada / condiÈ›iile colectÄƒrii: Noiembrie-Decembrie 2025. Colectare manualÄƒ prin desenare pe canvas digital HTML5.

2.2 Caracteristicile dataset-ului

NumÄƒr total de observaÈ›ii: 100 imagini.

NumÄƒr de caracteristici (features): 4096 (pixeli per imagine 64x64).

Tipuri de date: â˜ Numerice / â˜ Categoriale / â˜ Temporale / â˜‘ Imagini.

Format fiÈ™iere: PNG (Single Channel - Grayscale).

### 2.3 Descrierea fiecÄƒrei caracteristici

| CaracteristicÄƒ   | Tip       | Unitate | Descriere                     | Domeniu valori          |
|-----------------|-----------|---------|-------------------------------|------------------------|
| Imagine (X)      | matrice   | pixeli  | Imaginea semnÄƒturii redimensionatÄƒ | 64 x 64 px             |
| Canal Culoare    | numeric   | -       | Intensitate (Grayscale)       | 1                      |
| Intensitate Pixel| numeric   | -       | Valoarea luminozitÄƒÈ›ii        | 0 (Negru) â€“ 255 (Alb) |
| EtichetÄƒ (Y)     | categorial| -       | Clasa semnÄƒturii             | {0: Fals, 1: Autentic} |


3. Analiza Exploratorie a Datelor (EDA) â€“ Sintetic

3.1 Statistici descriptive aplicate

DistribuÈ›ia Claselor: Dataset-ul este perfect echilibrat:

50 SemnÄƒturi Autentice.

50 SemnÄƒturi False.

Analiza Dimensiunilor: Toate imaginile sunt standardizate la 64x64 pixeli.

3.2 Analiza calitÄƒÈ›ii datelor

Detectarea valorilor lipsÄƒ: Nu existÄƒ pixeli lipsÄƒ. Imaginile corupte (0 bytes) sunt ignorate automat.

ConsistenÈ›Äƒ: Formatul PNG lossless asigurÄƒ calitatea liniilor desenate.

3.3 Probleme identificate

Variabilitate: SemnÄƒturile cu mouse-ul prezintÄƒ un "tremur" specific (zgomot de cuantizare) faÈ›Äƒ de cele pe hÃ¢rtie.

Volum: Setul de 100 de date este mic, dar suficient pentru demonstrarea conceptului (Proof of Concept).

4. Preprocesarea Datelor

4.1 CurÄƒÈ›area datelor

Eliminare duplicatelor: Verificare manualÄƒ a folderelor.

Tratarea outlierilor: Eliminarea imaginilor complet albe (salvate eronat).

4.2 Transformarea caracteristicilor

Procesul este automatizat Ã®n codul Python:

Conversie Grayscale: Transformare RGB -> L (1 canal).

Redimensionare: Resize la 64x64 pixeli.

Normalizare: ÃmpÄƒrÈ›irea valorilor pixelilor la 255.0 => interval [0.0, 1.0].

4.3 Structurarea seturilor de date

ÃmpÄƒrÈ›ire realizatÄƒ:

80% â€“ Train: Pentru Ã®nvÄƒÈ›area ponderilor.

20% â€“ Validation: Pentru monitorizarea performanÈ›ei.

Principii respectate:

Shuffle: Amestecare aleatorie Ã®nainte de antrenare.

Stratificare: Asigurarea prezenÈ›ei ambelor clase Ã®n validare.

4.4 Salvarea rezultatelor preprocesÄƒrii

Datele nu sunt salvate intermediar pe disc, ci procesate "on-the-fly" Ã®n memoria RAM.

Modelul Final: Salvat ca semnatura_model.h5.

5. Diagrama Fluxului de Date

Mai jos este prezentat fluxul complet al datelor prin sistemul SVAS:

graph TD
    A[Utilizator] -->|DeseneazÄƒ SemnÄƒtura| B(InterfaÈ›Äƒ Web - HTML Canvas)
    B -->|ApasÄƒ 'VerificÄƒ'| C{JavaScript}
    C -->|Codificare Base64| D[HTTP POST Request]
    D -->|Trimite datele| E[Server Python Flask]
    
    subgraph "Backend AI (Pre-procesare & InferenÈ›Äƒ)"
    E -->|Decodare Imagine| F[Imagine BrutÄƒ]
    F -->|Resize 64x64 & Grayscale| G[Matrice 64x64x1]
    G -->|Normalizare /255.0| H[Tensor Input (0.0 - 1.0)]
    H -->|CNN Model| I[ReÈ›ea NeuronalÄƒ]
    I -->|PredicÈ›ie| J[Scor Sigmoid (0.0 - 1.0)]
    end
    
    J -->|Decizie (Prag > 0.8)| K[Verdict: AUTENTIC / FALS]
    K -->|RÄƒspuns JSON| C
    C -->|AfiÈ™are ColoratÄƒ| A


6. FiÈ™iere Generate Ã®n AceastÄƒ EtapÄƒ

svas_web.py: AplicaÈ›ia completÄƒ.

dataset/: Imaginile colectate.

semnatura_model.h5: Modelul antrenat.

README.md: DocumentaÈ›ia.

7. Stare EtapÄƒ

[x] StructurÄƒ repository configuratÄƒ.

[x] Dataset analizat È™i echilibrat (50/50).

[x] Date preprocesate (Pipeline automat implementat).

[x] Seturi train/validation utilizate Ã®n antrenare.

[x] AplicaÈ›ie Web funcÈ›ionalÄƒ È™i model antrenat.

[x] DocumentaÈ›ie actualizatÄƒ Ã®n README.
fa mi l sa arate mai frumos
