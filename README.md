ğŸ“˜ README â€“ Etapa 3: Analiza È™i PregÄƒtirea Setului de Date pentru ReÈ›ele Neuronale

Proiect: Sistem de Verificare a AutenticitÄƒÈ›ii SemnÄƒturilor (SVAS)

Student: Tranca Alexandru-Constantin

Grupa: 634 AB

InstituÈ›ie: Universitatea POLITEHNICA BucureÈ™ti â€“ FIIR

Disciplina: ReÈ›ele Neuronale

ğŸ§­ 1. Introducere

AceastÄƒ etapÄƒ a proiectului vizeazÄƒ colectarea, curÄƒÈ›area È™i preprocesarea datelor necesare pentru antrenarea reÈ›elei neuronale.
Obiectivul principal a fost constituirea unui dataset robust de semnÄƒturi digitale È™i dezvoltarea unei interfeÈ›e web (svas_web.py) care integreazÄƒ funcÈ›ionalitÄƒÈ›ile de achiziÈ›ie de date, antrenare a modelului È™i inferenÈ›Äƒ AI.

ğŸ“ 2. Structura Repository-ului

Arhitectura proiectului la finalul Etapei 3:

SVAS-Project/
â”œâ”€â”€ README.md                # DocumentaÈ›ia tehnicÄƒ a proiectului
â”œâ”€â”€ svas_web.py              # AplicaÈ›ia Web (InterfaÈ›Äƒ GraficÄƒ + Backend AI)
â”œâ”€â”€ semnatura_model.h5       # Modelul CNN antrenat È™i serializat
â”œâ”€â”€ dataset/                 # Setul de date colectat
â”‚   â”œâ”€â”€ Date autentice/      # 50 imagini cu semnÄƒturi originale (Clasa 1)
â”‚   â””â”€â”€ Date false/          # 50 imagini cu semnÄƒturi falsificate (Clasa 0)
â””â”€â”€ requirements.txt         # DependenÈ›e: tensorflow, flask, pillow, numpy



ğŸ—‚ï¸ 3. Descrierea Setului de Date

3.1 Sursa Datelor

Origine: Date generate propriu (First-party data).

MetodÄƒ de achiziÈ›ie: Desenare digitalÄƒ utilizÃ¢nd mouse-ul sau touchpad-ul, prin intermediul interfeÈ›ei aplicaÈ›iei web dezvoltate (svas_web.py).

Volum: Dataset iniÈ›ial compus din 100 de imagini.

3.2 DistribuÈ›ia Claselor

S-a menÈ›inut un echilibru perfect al claselor pentru a preveni bias-ul reÈ›elei neuronale Ã®n procesul de Ã®nvÄƒÈ›are:

ClasÄƒ

EtichetÄƒ (Label)

Descriere

NumÄƒr Mostre

Autentic

1

SemnÄƒturi realizate de titularul contului

50

Fals

0

ÃncercÄƒri de imitare sau semnÄƒturi aleatorii

50

3.3 Descrierea fiecÄƒrei caracteristici

Fiecare punct de date reprezintÄƒ o imagine procesatÄƒ, definitÄƒ prin urmÄƒtorii parametri:

CaracteristicÄƒ

Tip

Unitate

Descriere

Domeniu valori

Imagine (Input)

Matrice

Pixeli

Reprezentarea vizualÄƒ a semnÄƒturii (64x64)

0â€“255 (intensitate)

Canale Culoare

Numeric

-

NumÄƒrul de canale de culoare (Grayscale)

1

Valoare Pixel

Numeric

-

Valoarea normalizatÄƒ a luminozitÄƒÈ›ii

0.0 â€“ 1.0 (float)

EtichetÄƒ (Target)

Categorial

-

Clasa de apartenenÈ›Äƒ (Autentic/Fals)

{0, 1}

3.4 Probleme Identificate

Variabilitate de CapturÄƒ: SemnÄƒturile realizate cu mouse-ul prezintÄƒ un zgomot specific ("tremur") comparativ cu cele olografe. Modelul a fost configurat sÄƒ generalizeze peste aceste imperfecÈ›iuni.

Dimensiune Dataset: Volumul de 100 de imagini este minimal pentru Deep Learning, Ã®nsÄƒ suficient pentru validarea conceptului (Proof of Concept) Ã®n aceastÄƒ etapÄƒ.

ğŸ› ï¸ 4. Pipeline de Preprocesare

Ãnainte de a fi introduse Ã®n ReÈ›eaua NeuronalÄƒ, imaginile brute parcurg un flux automat de transformare implementat Ã®n Python:

Conversie Grayscale:

Transformarea imaginii din spectrul RGB (3 canale) Ã®n L (1 canal).

Scop: Eliminarea redundanÈ›ei cromatice È™i pÄƒstrarea doar a informaÈ›iei structurale (intensitatea liniilor).

Redimensionare (Resizing):

Standardizarea tuturor imaginilor la rezoluÈ›ia de 64x64 pixeli.

Scop: Reducerea complexitÄƒÈ›ii computaÈ›ionale È™i uniformizarea input-ului pentru CNN.

Normalizare:

ÃmpÄƒrÈ›irea valorilor pixelilor [0, 255] la 255.0.

Rezultat: Valori float Ã®n intervalul [0.0, 1.0], esenÈ›iale pentru convergenÈ›a rapidÄƒ a algoritmului de optimizare (Adam).

Data Augmentation (Implicit):

Variabilitatea naturalÄƒ indusÄƒ de desenarea manualÄƒ cu mouse-ul funcÈ›ioneazÄƒ ca o augmentare a datelor, oferind diferenÈ›e subtile Ã®ntre mostrele de antrenament.

ğŸ§  5. Arhitectura Modelului (Rezumat)

Modelul utilizat pentru validarea datelor Ã®n aceastÄƒ etapÄƒ este un CNN SecvenÈ›ial (Convolutional Neural Network):

Input Layer: (64, 64, 1)

Feature Extraction: 2 straturi de tip Conv2D urmate de MaxPooling2D pentru detectarea trÄƒsÄƒturilor vizuale locale.

Classification Head: Strat Dense (128 neuroni) + Dropout (0.5 pentru prevenirea overfitting-ului).

Output Layer: FuncÈ›ie de activare Sigmoid (probabilitate 0-1).

ğŸ’» 6. AplicaÈ›ia Web (Livrabil Etapa 3)

S-a dezvoltat un serviciu web (svas_web.py) utilizÃ¢nd framework-ul Flask, care oferÄƒ urmÄƒtoarele funcÈ›ionalitÄƒÈ›i:

âœ… InterfaÈ›Äƒ de CapturÄƒ: Desenarea semnÄƒturilor direct Ã®n browser folosind HTML5 Canvas.

âœ… Comunicare AsincronÄƒ: Transmiterea datelor cÄƒtre backend-ul Python prin Fetch API.

âœ… Modul de Antrenare: Posibilitatea de a re-antrena modelul la cerere, utilizÃ¢nd datele stocate Ã®n folderul dataset/.

âœ… InferenÈ›Äƒ Ã®n Timp Real: Verificarea instantanee a semnÄƒturilor noi È™i afiÈ™area verdictului.

ğŸ“¦ 7. FiÈ™iere Generate Ã®n AceastÄƒ EtapÄƒ

svas_web.py: Codul sursÄƒ complet al aplicaÈ›iei (Server Web + LogicÄƒ AI).

dataset/: Directorul conÈ›inÃ¢nd cele 100 de imagini colectate È™i clasificate.

semnatura_model.h5: FiÈ™ierul binar al modelului antrenat, gata de utilizare.

README.md: DocumentaÈ›ia tehnicÄƒ actualizatÄƒ a proiectului.

âœ”ï¸ 8. Status EtapÄƒ

$$x$$

 Colectare date: 50 mostre Autentice / 50 mostre False salvate È™i structurate corect.

$$x$$

 CurÄƒÈ›are date: Eliminarea imaginilor goale sau corupte.

$$x$$

 Implementare Preprocesare: Integrarea funcÈ›iilor de Resize È™i Normalizare Ã®n cod.

$$x$$

 Dezvoltare InterfaÈ›Äƒ: AplicaÈ›ie Web funcÈ›ionalÄƒ È™i testatÄƒ.

$$x$$

 Validare: Modelul antrenat a atins o acurateÈ›e preliminarÄƒ satisfÄƒcÄƒtoare (>90%).
Nu imi schimba nimic din el doar fa mi l sa arate bine ca sa il pun intru un fisier readme de pe github
